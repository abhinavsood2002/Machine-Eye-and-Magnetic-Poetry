- Basic Yolo Object detection is not sufficient to accurately detect hands
- Using the motion estimation by feature tracking example to calculate average movements is also very inefficient and inaccurate
- Multiple people have tried finetuning yolo or using other models on OAK-D devices with hands specifically. Here an example exists that tries to predict ASL letters on the luxonis website  https://github.com/cortictechnology/hand_asl_recognition
- This gives flexibility for future gesture detection
- Some code needed to be changed (fonts to pillow and other small errors to make code work)